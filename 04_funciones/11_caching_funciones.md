---
layout: default
title: üìï Caching Funciones
parent: üïπ 04. Funciones
description: Python nos permite realizar caching de funciones, lo que permite ahorrar en tiempo de ejecuci√≥n cuando el valor con el que se llama a la funci√≥n ya ha sido calculado anteriormente. El caching puede ser implementado por nosotros mismos usando un diccionario, o tambi√©n podemos usar el lru_cache del paquete functools.
order: 49
nav_order: j
permalink: /caching-python
---

# Caching de Funciones

El [cach√©](https://es.wikipedia.org/wiki/Cach%C3%A9_(inform%C3%A1tica)) es un t√©rmino muy usado en inform√°tica, y hace referencia al almacenamiento de resultados previos para su posterior reutilizaci√≥n, lo que permite reducir el tiempo de respuesta. Por ejemplo, si llamamos a una funci√≥n con un determinado par√°metro y acto seguido realizamos la misma llamada, ser√≠a interesante **reutilizar el primer resultado** para no tener que calcularlo otra vez. Existen por lo tanto dos posibilidades:
* Si ejecutamos la funci√≥n y el resultado no ha sido calculado con anterioridad, se calcula y se almacena por si fuera √∫til en el futuro. Esto se conoce como **cache miss**.
* Si ejecutamos la funci√≥n y el cach√© tiene almacenado el resultado para esa operaci√≥n, en vez de calcular otra vez la salida la podemos reutilizar, lo que se conoce como **cache hit**. Dado que estamos reutilizando un valor ya calculado, generalmente el tiempo de respuesta ser√° menor.


Por suerte, Python nos permite a√±adir *caching* a nuestras [funciones](/funciones-en-python), pero antes de implementarlo es conveniente hacer un an√°lisis sobre nuestro programa y determinar si merece la pena. Algunas cosas a tener en cuenta:
* El *caching* es especialmente √∫til cuando trabajamos con **funciones muy intensivas en c√°lculo**, lo que hace que reutilizar el valor del cach√© reduzca notablemente el tiempo de respuesta.
* Es necesario conocer (a nivel estad√≠stico) **la distribuci√≥n de los argumentos con los que se llama la funci√≥n**. Si la funci√≥n bajo estudio se llama con valores muy dispares y apenas repetidos, el *caching* poco ayudar√°, ya que apenas tendremos un *cache hit*.
* El uso de un cach√© puede mejorar el tiempo de respuesta, pero frecuentemente **se paga en un incremento del uso de memoria**. Tambi√©n es necesario decidir el n√∫mero de valores a almacenar.

A continuaci√≥n veremos como implementar *caching* en Python, pudiendo hacerlo con [diccionarios](/diccionarios-en-python) o utilizando la librer√≠a `functools`. Para ejemplificarlo, veremos como implementar un cach√© en nuestro c√≥digo de [n√∫meros primos](/numeros-primos-python) visto anteriormente, empleando ambas formas.

```python
def es_primo(num):
    for n in range(2, num):
        if num % n == 0:
            return False
    return True
```

# Caching con Diccionarios

La primera forma de realizarlo es usando un [diccionario](/diccionarios-en-python) como cach√©. N√≥tese que este es un ejemplo did√°ctico, y que obvia algunos factores. Como puedes ver tenemos claramente diferenciado el *cache hit* y el *cache miss*. Si el valor no est√° en el cach√© se calcula y se devuelve.

```python
def es_primo_concache(num, _cache={}):
    if num not in _cache:
        _cache[num] = True
        for n in range(2, num):
            if num % n == 0:
                _cache[num] = False
                break
    return _cache[num]
```

Dado que `es_primo` es bastante intensivo en c√°lculo, cuando usamos n√∫meros grandes el ahorro puede ser muy significativo. En el siguiente c√≥digo podemos ver como la primera vez que ejecutamos la funci√≥n, se tardan 3.5 segundos, ya que el resultado tiene que ser calculado. Sin embargo la segunda vez que la llamamos con la misma entrada, tenemos un *cache hit*, por lo que el valor ya no es calculado sino recuperado del cach√©, tardando microsegundos.

```python

import time
tic = time.time()
es_primo_concache(25565479)
print(time.time() - tic)

tic = time.time()
es_primo_concache(25565479)
print(time.time() - tic)

# 3.5551438331604004
# 4.0531158447265625e-06
```

# Caching con functools y lru_cache

La segunda forma de realizarlo, y un poco m√°s sofisticada es usando `lru_cache`, un [decorador](/decoradores-python) que viene con la librer√≠a est√°ndar [functools](https://docs.python.org/3/library/functools.html). La mayor ventaja es que no necesitamos modificar la funci√≥n. N√≥tese que `maxsize` nos permite indicar el n√∫mero m√°ximo de valores que queremos almacenar en el cach√©.

```python
from functools import lru_cache

@lru_cache(maxsize=32)
def es_primo_concache(num):
    for n in range(2, num):
        if num % n == 0:
            return False
    return True
```

Por lo tanto si ahora llamamos a nuestra funci√≥n con los mismos valores, podemos ver como la primera vez tarda 3.9 segundos, pero la segunda apenas tarda unos microsegundos.

```python
import time
tic = time.time()
es_primo_concache(25565479)
print(time.time() - tic)

tic = time.time()
es_primo_concache(25565479)
print(time.time() - tic)

# 3.9316678047180176
# 3.0994415283203125e-06
```

En el caso de que queramos limpiar el cach√© de nuestra funci√≥n, podemos realizar lo siguiente.

```python
es_primo_concache.cache_clear()
```